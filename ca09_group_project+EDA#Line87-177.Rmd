---
title: "Final Group Project: AirBnB analytics"
date: "12 Oct 2021"
author: "Reading Time: About 8 minutes"
output:
  html_document:
    highlight: zenburn
    theme: flatly
    toc: yes
    toc_float: yes
    number_sections: yes
    code_folding: show
---


```{r setup, include=FALSE}
# leave this chunk alone
options(knitr.table.format = "html") 
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
  comment = NA, dpi = 300)
```


```{r load-libraries, echo=FALSE}
rm(list = ls())
library(tidyverse) # the usual stuff: dplyr, readr, and other goodies
library(lubridate) # to handle dates
library(GGally) # for correlation-scatter plot matrix
library(ggfortify) # to produce residual diagnostic plots
library(rsample) # to split dataframe in training- & testing sets
library(janitor) # clean_names()
library(broom) # use broom:augment() to get tidy table with regression output, residuals, etc
library(huxtable) # to get summary table of all models produced
library(kableExtra) # for formatting tables
library(moderndive) # for getting regression tables
library(skimr) # for skim
library(mosaic)
library(leaflet) # for interactive HTML maps
library(tidytext)
library(viridis)
library(leaps)
library(vroom)
```




In your final group assignment you have to analyse data about Airbnb listings and fit a model to predict the total cost for two people staying 4 nights in an AirBnB in a city. You can download AirBnB data from [insideairbnb.com](http://insideairbnb.com/get-the-data.html){target="_blank"}; it was originally scraped from airbnb.com. 

The following [Google sheet](https://docs.google.com/spreadsheets/d/1QrR-0PUGVWvDiVQL4LOk7w-xXwiDnM3dDtW6k15Hc7s/edit?usp=sharing) shows which cities you can use; please choose one of them and add your group name next to it, e.g., A7, B13. No city can have more than 2 groups per stream working on it; if this happens, I will allocate study groups to cities with the help of R's sampling.


All of the listings are a GZ file, namely they are archive files compressed by the standard GNU zip (gzip) compression algorithm. You can download, save and extract the file if you wanted, but `vroom::vroom()` or `readr::read_csv()` can immediately read and extract this kind of a file. You should prefer `vroom()` as it is faster, but if vroom() is limited by a firewall, please use `read_csv()` instead.


`vroom` will download the *.gz zipped file, unzip, and provide you with the dataframe. 


```{r load_data, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}

# use cache=TRUE so you dont donwload the data everytime you knit

listings <- vroom("http://data.insideairbnb.com/belgium/bru/brussels/2021-09-24/data/listings.csv.gz") %>% 
       clean_names()

#the list of columns which we found redundant and excluded from the analysis:
redundant_columns <- c("id", "listing_url", "scrape_id", "last_scraped", "name", "description", "neighborhood_overview", "picture_url", "host_id", "host_url", "host_name", "host_since", "host_location", "host_about", "host_thumbnail_url", "host_picture_url", "host_verifications", "neighborhood_group_cleansed", "bathrooms", "minimum_minimum_nights", "minimum_maximum_nights", "maximum_maximum_nights", "maximum_minimum_nights", "minimum_nights_avg_ntm", "maximum_nights_avg_ntm", "calendar_updated", "calendar_last_scraped", "license", "host_neighbourhood" , "neighbourhood", "neighbourhood_group_cleansed", "host_response_time", "host_response_rate", "host_acceptance_rate", "host_total_listings_count")
```


Even though there are many variables in the dataframe, here is a quick description of some of the variables collected, and you can find a [data dictionary here](https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit#gid=982310896)

- `price` = cost per night 
- `property_type`: type of accommodation (House, Apartment, etc.)
- `room_type`:

  - Entire home/apt (guests have entire place to themselves)
  - Private room (Guests have private room to sleep, all other rooms shared)
  - Shared room (Guests sleep in room shared with others)

- `number_of_reviews`: Total number of reviews for the listing
- `review_scores_rating`: Average review score (0 - 100)
- `longitude` , `latitude`: geographical coordinates to help us locate the listing
- `neighbourhood*`: three variables on a few major neighbourhoods in each city 


# Exploratory Data Analysis (EDA)

## Raw values
```{r}
glimpse(listings)
```
- How many variables/columns? How many rows/observations?
**Answer:** 74 variables and 5442 rows.
- Which variables are numbers?
**Answer:** Columns which have a type of <dbl>, eg.id, scrape_id, host_id, host_listings_count, host_total_listings_count, latitude, longitude...
- Which are categorical or *factor* variables (numeric or character variables with variables that have a fixed and known set of possible values?
**Answer:** Some columns with a type of <chr>, including host_response_time, host_neighbourhood, neighbourhood_cleansed, property_type, room_type. 

##Summary statistics
```{r}
skim(listings)
```

##Visualizations
1. The room scale effects in regression
- 'accommodates' and 'beds' have a correlation of 0.785, thus should not be both included in regression
```{r}
listings$price <- readr::parse_number(listings$price)

listings <- listings %>% 
  mutate(lg_price = log(price)) 

ggpairs(listings, columns = c("lg_price", "bedrooms", "beds", "accommodates"))
```

2. The availability effects in regression
- 'availability_30' has the largest correlation with price
```{r}

ggpairs(listings, columns = c("lg_price", "availability_30","availability_60", "availability_90", "availability_365"))
```

3. The review effects in regression 
- we can select one of those review scores to include 
- 'reviews_per_month' may has a significant effect on price
```{r}

ggpairs(listings, columns = c("lg_price", "number_of_reviews", "review_scores_rating", "review_scores_accuracy", "review_scores_cleanliness", "review_scores_checkin", "review_scores_communication", "review_scores_location", "review_scores_value", "reviews_per_month"))
```

4. potential variables
```{r}
ggpairs(listings, columns = c("lg_price", "bedrooms", "accommodates", "availability_30", "number_of_reviews", "review_scores_cleanliness", "reviews_per_month"))
```

5. boxplot of neighbourhood_cleansed
- Bruxelles may be considered into model
```{r}

listings %>% 
  group_by(neighbourhood_cleansed) %>% 
  ggplot() +
  geom_boxplot(aes(x = factor(neighbourhood_cleansed), y = lg_price)) +
  theme_bw() + 
  geom_hline(yintercept = 4.33, color = "red", size = 0.7) +
  labs(x = "neighbourhood_cleansed", y = "log(price)")
```

6. histogram of property type
```{r}

listings %>% 
  group_by(property_type) %>% 
  ggplot(aes(x = lg_price)) +
  geom_histogram() +
  facet_wrap(~property_type, scales= "free")+
  theme_bw() + 
  labs(x = "log(price)", y = "")
```

7. histogram of room type
```{r}

listings %>% 
  group_by(room_type) %>% 
  ggplot(aes(x = lg_price)) +
  geom_histogram() +
  facet_wrap(~room_type, scales= "free")+
  theme_bw() + 
  labs(x = "log(price)", y = "")
```


- What are the correlations between variables? Does each scatterplot support a linear relationship between variables? Do any of the correlations appear to be conditional on the value of a categorical variable?
**Answer:** The correlations can not exactly be defined as linear through the scatterplot. However, most pairs have a upward and downward of trend, especially for log(price). For property type and room type, the price has a obvious correlation with some specific type which may be conditional correlations. 

## Data wrangling

Once you load the data, it's always a good idea to use `glimpse` to see what kind of variables you have and what data type (`chr`, `num`, `logical`, `date`, etc) they are. 

Notice that some of the price data (`price`) is given as a character string, e.g., "$176.00"

Since `price` is a quantitative variable, we need to make sure it is stored as numeric data `num` in the dataframe. To do so, we will first use `readr::parse_number()` which drops any non-numeric characters before or after the first number

```{r}
listings$price <- readr::parse_number(listings$price)

```

```{r}
typeof(listings$price)

listings %>% group_by(property_type) %>% summarise(counts = count(property_type)) %>% arrange(desc(counts))
```


Use `typeof(listing$price)` to confirm that `price` is now stored as a number.


## Propery types


Next, we look at the variable `property_type`. We can use the `count` function to determine how many categories there are their frequency. What are the top 4 most common property types? What proportion of the total listings do they make up? 

Since the vast majority of the observations in the data are one of the top four or five property types, we would like to create a simplified version of `property_type` variable that has 5 categories: the top four categories and `Other`. Fill in the code below to create `prop_type_simplified`.

```{r}
listings <- listings %>%
  mutate(prop_type_simplified = case_when(
    property_type %in% c("Entire rental unit","Private room in rental unit", "Entire condominium (condo)","Private room in residential home") ~ property_type, 
    TRUE ~ "Other"
  ))
  
```
Use the code below to check that `prop_type_simplified` was correctly made.

```{r}
listings %>%
  count(property_type, prop_type_simplified) %>%
  arrange(desc(n))      

#delete the variable we no longer need:
listings$property_type <- NULL
```        

Airbnb is most commonly used for travel purposes, i.e., as an alternative to traditional hotels. We only want to include  listings in our regression analysis that are intended for travel purposes:

- What are the  most common values for the variable `minimum_nights`? 
```{r}

listings %>% group_by(minimum_nights) %>% summarize(values = count(minimum_nights)) %>% arrange(desc(values))
```
- Is ther any value among the common values that stands out? 

**Answer**: the value of 90 days, which likely stands out as a proxy to long-term rent.


- What is the likely intended purpose for Airbnb listings with this seemingly unusual value for `minimum_nights`?

**Answer**: Long-term rent

Filter the airbnb data so that it only includes observations with `minimum_nights <= 4`

```{r}
listings <- listings %>% filter(minimum_nights <= 4)

 

```
        
# Mapping 

Visualisations of feature distributions and their relations are key to understanding a data set, and they can open up new lines of exploration. While we do not have time to go into all the wonderful geospatial visualisations one can do with R, you can use the following code to start with a map of your city, and overlay all AirBnB coordinates to get an overview of the spatial distribution of AirBnB rentals. For this visualisation we use the `leaflet` package, which includes a variety of tools for interactive maps, so you can easily zoom in-out, click on a point to get the actual AirBnB listing for that specific point, etc.

The following code, having downloaded a dataframe `listings` with all AirbnB listings in Milan, will plot on the map all AirBnBs where `minimum_nights` is less than equal to four (4). You could learn more about `leaflet`, by following [the relevant Datacamp course on mapping with leaflet](https://www.datacamp.com/courses/interactive-maps-with-leaflet-in-r)

**Note:** below we added the visualization with a heatmap (i.e. color is differentiated depending on the price of accomodation)

```{r, out.width = '80%'}

#Create a heatmap of the prices:
listings$price_cuts <- cut(listings$price, 
                        quantile(listings$price), include.lowest = T,
                        labels = c('<50%', '50-100%', '100-150%', '150-200%'))
heatmap_colors <- colorFactor(palette = 'RdYlGn', listings$price_cuts)

leaflet(data = filter(listings, minimum_nights <= 4)) %>% 
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1, 
                   color = ~heatmap_colors(listings$price_cuts), 
                   fillOpacity = 0.3, 
                   popup = ~listing_url,
                   label = ~prop_type_simplified)
#delete the redundant column:
listings$price_cuts <- NULL


#Note - we need to add legend to this :)
```

    
# Regression Analysis

For the target variable $Y$, we will use the cost for two people to stay at an Airbnb location for four (4) nights. 

Create a new variable called `price_4_nights` that uses `price`, and `accomodates` to calculate the total cost for two people to stay at the Airbnb property for 4 nights. This is the variable $Y$ we want to explain.

Use histograms or density plots to examine the distributions of `price_4_nights` and `log(price_4_nights)`. Which variable should you use for the regression model? Why?

Fit a regression model called `model1` with the following explanatory variables: `prop_type_simplified`, `number_of_reviews`, and `review_scores_rating`. 

- Interpret the coefficient `review_scores_rating` in terms of `price_4_nights`.
- Interpret the coefficient of `prop_type_simplified` in terms of `price_4_nights`.

We want to determine if `room_type` is a significant predictor of the cost for 4 nights, given everything else in the model. Fit a regression model called model2 that includes all of the explananatory variables in `model1` plus `room_type`. 

```{r}

#We should find relevant variables for regressing price_4_nights
data <- listings %>% filter(accommodates >= 2)
data <- data %>% mutate(price_4_nights = 4*2*price)
data %>% ggplot(aes(x = bedrooms, y = price_4_nights))+ 
  geom_point()

#Delete the variable price which is no more relevant:
data$price <- NULL

#build regression model 
model1 <- summary(lm(price_4_nights ~ prop_type_simplified+number_of_reviews+review_scores_rating, data = data))

#print(model1$coefficients)

#build model 2:

model2 <- lm(price_4_nights ~ prop_type_simplified+number_of_reviews+review_scores_rating+room_type, data = data)
model2 <- summary(model2)
model2$coefficients
```
Comments to this sectio - please add comments.


**Next** - once we continue moving to our new model, we need to do the following:
-feature engineering;
-exclude the redundant/uninformative/NA columns, as per the variable `redundant_columns`;
-decide on the functional form of `price_4_nights` - especially whether we should try the log-transformation.

```{r}

#Perform some more EDA on the reduced dataset:
#Have a look at prices across different neigbourhoods:
data %>% 
  ggplot(aes(x = neighbourhood_cleansed))+
  geom_boxplot(aes(y = price_4_nights))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

#Looks like we need some outliers deleted. Let's do it neighbourhood-wise:

data <- data %>%
  group_by(neighbourhood_cleansed) %>%
  subset(price_4_nights > quantile(price_4_nights, probs = 0.25)-1.5*(quantile(price_4_nights, probs = 0.75)-quantile(price_4_nights, probs = 0.25)) & price_4_nights < quantile(price_4_nights, probs = 0.75)+1.5*(quantile(price_4_nights, probs = 0.75)-quantile(price_4_nights, probs = 0.25)))%>%
  ungroup()

data %>% 
  ggplot(aes(x = neighbourhood_cleansed))+
  geom_boxplot(aes(y = price_4_nights))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
#Based on this inference, we can see that only for Berchem-Sainte-Agathe and Bruxelles districts is median price significantly different from the general group. So, we can decrese the number of classes in the variable neighbourhood_cleansed:
data <- data %>%
  mutate(neighbourhood_cleansed = case_when(
    neighbourhood_cleansed %in% c("Berchem-Sainte-Agathe","Bruxelles") ~ neighbourhood_cleansed, 
    TRUE ~ "Other"
  ))

#Transform the variable bathrooms_text into a numeric variable:

try_digit <- as.numeric(mapply(gsub, data$bathrooms_text, pattern ="\\D", replacement = ""))
data <- data %>%
  mutate(bathrooms_text = try_digit)

#Count amenities for each listing, make it a new variable:
amenities2 <- mapply(strsplit, data$amenities, ",")
amenities2 <- mapply(function(x){sum(lengths(x))}, amenities2)
amenities2 <- unname(amenities2)
data <- data %>% mutate(amenities = amenities2)


#Now we can have a look at QQ-plots of price_4_nights:
qqnorm(data$price_4_nights, pch = 1, frame = FALSE)
qqline(data$price_4_nights, col = "darkgrey", lwd = 2)

qqnorm(log(data$price_4_nights), pch = 1, frame = FALSE)
qqline(log(data$price_4_nights), col = "darkgrey", lwd = 2)
```
Key takeaways from this section:

-To be added.


```{r}
#Prepare the dataset for model creation:
#Delete columns with low explanatory power (as per redundant_columns):

data <- data[, !colnames (data) %in% redundant_columns, drop = FALSE]

#We have deleted the majority of columns with high percentage of NAs, so we can
#use na.omit without significant loss of information:

data <- na.omit(data)




```

```{r}
#We can compare models of different complexity using the forward stepwise selection algorithm, and have a look at the results:
library(leaps)
library(data.table)
regression_forward <- summary(regsubsets(price_4_nights ~.+log(reviews_per_month), data = data, method = "forward", nvmax = 41))
results <- data.table(vars = seq(0,40,1), BIC = regression_forward$bic, 
                      CP = regression_forward$cp, R_sq_adj = regression_forward$adjr2,
                      RMSE = sqrt(regression_forward$rss/length(data$price_4_nights)))
results <- results %>%
  pivot_longer(!vars, names_to = "metric", values_to = "value")
results %>%
  ggplot(aes(x = vars, y = value))+
  geom_point(color = "red", shape = 21, fill = "white", size = 1)+
  geom_line(color = "red")+
  facet_wrap(~metric, scales = "free")+
  theme_bw()

```
We choose BIC as the metric for evaluation of out-of-sample performance of our model. Although minimum BIC is attained at approximately 20 predictors (including multi-level factors), we can notice that the increase in performance is infinitesimal for N>12 predictors, approximately. So, we choose model with complexity **k=12**.

Let us specify this model below:

```{r}
which_variables <- regression_forward[["which"]][12,]
print(which_variables[which_variables == TRUE])

#Let's print out which varibales we choose:
```

```{r}
#Next, let us build our final regression model:

data_filtered <- data[, c("price_4_nights","neighbourhood_cleansed", "room_type","bedrooms", "availability_30", "calculated_host_listings_count_entire_homes", "reviews_per_month", "host_listings_count", "accommodates", "amenities", "review_scores_cleanliness", "bathrooms_text", "beds", "host_is_superhost")]
data_filtered <- data_filtered[, reviews_per_month = log(reviews_per_month)]

model_final <- summary(lm(log(price_4_nights) ~.-bathrooms_text-beds-host_is_superhost, data = data_filtered))
#Get the coefficients:

print(model_final$coefficients)

#As we can see, all coefficient are highly significant

```

## Further variables/questions to explore on our own

Our dataset has many more variables, so here are some ideas on how you can extend your analysis

1. Are the number of `bathrooms`, `bedrooms`, `beds`, or size of the house (`accomodates`) significant predictors of `price_4_nights`? Or might these be co-linear variables?

**Answer:** As shown above, `bedrooms` and `accomodates` are significant predictors of the target variable at $\alpha=5\%$ significance level. Let's now build a regression model and evaluate the effects of other variables:

```{r}
model_q1 <- summary(lm(log(price_4_nights) ~.-host_is_superhost, data = data_filtered))
print(model_q1$coefficients[15:16,])
```

Hence, both `bathrooms` and `beds`are insignificant predictors of `log(price_4_nights` at $\alpha = 5\%$ significance level, given the p-values of approx. $96\%$ and $7\%$,respectively

Now, let's create a pairwise correlation plot to account for prossible collinearity across these variables:

```{r}
data_filtered[,c("bathrooms_text", "bedrooms", "beds")] %>%
  ggpairs()
```
All these 3 variables have positive pairwise correlations. However, since all these pairwise correlations lie below the threshold of 0.7 (generally accepted threshold for strong positive correlation), we cannot infer significant collinearity between these variables.

1. Do superhosts `(host_is_superhost`) command a pricing premium, after controlling for other variables?

**Answer:** to find it out, let's build another OLS model with this variable included:

```{r}
model_q2 <- model_q1 <- summary(lm(log(price_4_nights) ~., data = data_filtered))
print(model_q1$coefficients[17,])
```
Hence, `host_is_superhost` actually commands a pricing premium of approx. $12, holding all the other variables constant. However, the coefficient of this variable is completely insignificant (P-value of approx. 33%). Consequently, this predictor should not be included in the model, and its coefficient is not statistically significant.


1. Some hosts allow you to immediately book their listing (`instant_bookable == TRUE`), while a non-trivial proportion don't. After controlling for other variables, is `instant_bookable` a significant predictor of `price_4_nights`?

Let's create another model to find out:

```{r}
data_filtered <- data_filtered %>% 
  mutate(instant_bookable = data$instant_bookable)
model_q2 <- summary(lm(log(price_4_nights) ~.-bathrooms_text-beds-host_is_superhost, data = data_filtered))
print(model_q1$coefficients[15,])


#The coefficient for instant_bookable is stated below:
```
As we can see, the coefficient of `instant_bookable` is actually insignificant at $\alpha=5%$ significance level. The pricing premium is near-zero even once the log-transformation of response is taken into account. This variable should not be used in our final model.



1. For all cities, there are 3 variables that relate to neighbourhoods: `neighbourhood`, `neighbourhood_cleansed`, and `neighbourhood_group_cleansed`. There are typically more than 20 neighbourhoods in each city, and it wouldn't make sense to include them all in your model. Use your city knowledge, or ask someone with city knowledge, and see whether you can group neighbourhoods together so the majority of listings falls in fewer (5-6 max) geographical areas. You would thus need to create a new categorical variabale `neighbourhood_simplified` and determine whether location is a predictor of `price_4_nights`

**Answer**. We covered this question at the feature engineering stage. Creating a facet of `price_4_nights` boxplots across neighbourhoods, we found out that median values, Q1, and Q3 are actually equal across the majority of neighbourhoods. Only 2 of them stand out in terms of median price:
-"Berchem-Sainte-Agathe" has cheaper accommodation, on average.

-"Bruxelles" has more expensive accommodation, on average.

Hence, the author of this code divided the variable `neighbourhood_cleansed` into 3 sub-groups: "Berchem-Sainte-Agathe", "Bruxelles", and "Other", which summarizes the rest of neighbourhoods with a relatively uniform pricing scheme for Airbnb accomodations.

1. What is the effect of `avalability_30` or `reviews_per_month` on `price_4_nights`, after we control for other variables?

These variables are already included in our linear regression model. We can easily get the coefficients:

```{r}
print(model_final$coefficients[c(8,10),])
```
Both coefficients are very significant. 

**Interpret the coefficients given the log-transformation of response!**


## Diagnostics, collinearity, summary tables

As you keep building your models, it makes sense to:

1. Check the residuals, using `autoplot(model_x)`

```{r}

model_final <- lm(log(price_4_nights) ~.-bathrooms_text-beds-host_is_superhost-instant_bookable, data = data_filtered)
autoplot(model_final)
```
**Add comments**?

1. As you start building models with more explanatory variables, make sure you use `car::vif(model_x)`` to calculate the **Variance Inflation Factor (VIF)** for your predictors and determine whether you have colinear variables. A general guideline is that a VIF larger than 5 or 10 is large, and your model may suffer from collinearity. Remove the variable in question and run your model again without it.



1. Create a summary table, using `huxtable` (https://mfa2022.netlify.app/example/modelling_side_by_side_tables/) that shows which models you worked on, which predictors are significant, the adjusted $R^2$, and the Residual Standard Error.
1. Finally, you must use the best model you came up with for prediction. Suppose you are planning to visit the city you have been assigned to over reading week, and you want to stay in an Airbnb. Find Airbnb's in your destination city that are apartments with a private room, have at least 10 reviews, and an average rating of at least 90. Use your best model to predict the total cost to stay at this Airbnb for 4 nights. Include the appropriate 95% interval with your prediction. Report the point prediction and interval in terms of `price_4_nights`. 
  - if you used a log(price_4_nights) model, make sure you anti-log to convert the value in $. You can read more about [hot to interpret a regression model when some variables are log transformed here](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-do-i-interpret-a-regression-model-when-some-variables-are-log-transformed/)


# Deliverables


- By midnight on Monday 18 Oct 2021, you must upload on Canvas a short presentation (max 4-5 slides) with your findings, as some groups will be asked to present in class. You should present your Exploratory Data Analysis, as well as your best model. In addition, you must upload on Canvas your final report, written  using R Markdown to introduce, frame, and describe your story and findings. You should include the following in the memo:

1. Executive Summary: Based on your best model, indicate the factors that influence `price_4_nights`.
This should be written for an intelligent but non-technical audience. All
other sections can include technical writing.
2. Data Exploration and Feature Selection: Present key elements of the data, including tables and
graphs that help the reader understand the important variables in the dataset. Describe how the
data was cleaned and prepared, including feature selection, transformations, interactions, and
other approaches you considered.
3. Model Selection and Validation: Describe the model fitting and validation process used. State
the model you selected and why they are preferable to other choices.
4. Findings and Recommendations: Interpret the results of the selected model and discuss
additional steps that might improve the analysis
  
  

Remember to follow R Markdown etiquette rules and style; don't have the Rmd output extraneous messages or warnings, include summary tables in nice tables (use `kableExtra`), and remove any placeholder texts from past Rmd templates; in other words, (i.e. I don't want to see stuff I wrote in your final report.)
  
  
# Rubric

Your work will be assessed on a rubric which you can find here


```{r rubric, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "rubric.png"), error = FALSE)
```


# Acknowledgements

- The data for this project is from [insideairbnb.com](insideairbnb.com)